import uvicorn
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from fastapi.middleware.cors import CORSMiddleware
from typing import List, Dict, Any
import json
import os

# âœ¨ OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ import
import openai

# âœ¨ dotenv ë¼ì´ë¸ŒëŸ¬ë¦¬ import
from dotenv import load_dotenv

# âœ¨ .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ë¥¼ ë¡œë“œ
load_dotenv()


# --- Pydantic ëª¨ë¸ ì •ì˜ (ë³€ê²½ ì—†ìŒ) ---
class TextIn(BaseModel):
    text: str

class InterviewDataIn(BaseModel):
    data: List[Dict[str, Any]]

class BatchAnalysisIn(BaseModel):
    data: List[Dict[str, Any]]
    column_name: str


# --- FastAPI ì•± ë° CORS ì„¤ì • (ë³€ê²½ ì—†ìŒ) ---
app = FastAPI()
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# --- OpenAI í´ë¼ì´ì–¸íŠ¸ ì„¤ì • (ë³€ê²½ ì—†ìŒ) ---
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

try:
    if not OPENAI_API_KEY:
        raise ValueError("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")

    openai_client = openai.OpenAI(api_key=OPENAI_API_KEY)
    GPT_MODEL_NAME = "gpt-4o-mini" # ì¶”ì²œ: ë¹„ìš© íš¨ìœ¨ì ì¸ ê³ ì„±ëŠ¥ ëª¨ë¸
    print("âœ… OpenAI (GPT) í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì„±ê³µ!")

except Exception as e:
    print(f"ğŸ’¥ OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    openai_client = None


# --- ì—”ë“œí¬ì¸íŠ¸ 1: GPT ê¸°ë°˜ í‚¤ì›Œë“œ ì¶”ì¶œ (ë°°ì¹˜ ì²˜ë¦¬) (ë³€ê²½ ì—†ìŒ) ---
@app.post("/extract-keywords-llm-batch")
async def extract_keywords_llm_batch(payload: BatchAnalysisIn):
    """
    ì „ì²´ ë°ì´í„°ì™€ ë¶„ì„í•  ì»¬ëŸ¼ëª…ì„ ë°›ì•„, 10ê°œì”© ë¬¶ì–´ GPTë¡œ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ê³  ê²°ê³¼ë¥¼ í•œ ë²ˆì— ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    if not openai_client:
        raise HTTPException(status_code=500, detail="OpenAI í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    column = payload.column_name
    
    entries = [
        (row['uniqueId'], row.get(column, ''))
        for row in payload.data
        if row.get(column) and isinstance(row.get(column), str) and row.get(column).strip()
    ]
    if not entries:
        return {}

    chunks = [entries[i:i + 10] for i in range(0, len(entries), 10)]
    final_result = {}

    for chunk in chunks:
        user_prompt = "\n\n".join(
            [f"--- ID: {uid} ---\n{opinion}" for uid, opinion in chunk]
        )

        system_prompt = f"""
ë‹¹ì‹ ì€ SKì—”ë¬´ë¸Œì˜ HR ë°ì´í„° ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì•„ë˜ì— ì œì‹œëœ ê° êµ¬ì„±ì›ì˜ ì˜ê²¬(`{column}`)ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œë¥¼ ê°ê° ì¶”ì¶œí•˜ì„¸ìš”.
í‚¤ì›Œë“œëŠ” í•´ë‹¹ êµ¬ì„±ì›ì˜ í•µì‹¬ì ì¸ ì˜ê²¬, ìš”êµ¬ì‚¬í•­ì„ ë‚˜íƒ€ë‚´ì•¼ í•©ë‹ˆë‹¤.
ë°˜ë“œì‹œ ì•„ë˜ ìš”ì²­ëœ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì•¼ í•˜ë©°, ë‹¤ë¥¸ ì„¤ëª…ì€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.

- ê° í‚¤ì›Œë“œëŠ” 'word'ì™€ 'score'ë¥¼ í‚¤ë¡œ ê°–ëŠ” ê°ì²´ì—¬ì•¼ í•©ë‹ˆë‹¤.
- ìµœì¢… ê²°ê³¼ëŠ” ê° 'ID'ë¥¼ í‚¤ë¡œ í•˜ê³ , í‚¤ì›Œë“œ ê°ì²´ ë°°ì—´ì„ ê°’ìœ¼ë¡œ í•˜ëŠ” JSON ê°ì²´ì—¬ì•¼ í•©ë‹ˆë‹¤.

[ì‘ë‹µ í˜•ì‹ ì˜ˆì‹œ]
{{
  "row_0": [ {{"word": "ì„±ì¥", "score": 0.91}}, {{"word": "í”„ë¡œì íŠ¸", "score": 0.85}} ],
  "row_1": [ {{"word": "ë¦¬ë”ì‹­", "score": 0.87}}, {{"word": "ì†Œí†µ", "score": 0.82}} ],
  "row_2": [ {{"word": "ë³´ìƒ", "score": 0.95}} ]
}}
"""

        try:
            response = openai_client.chat.completions.create(
                model=GPT_MODEL_NAME,
                response_format={"type": "json_object"},
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.7,
            )
            content = response.choices[0].message.content
            batch_result = json.loads(content)
            final_result.update(batch_result)

        except Exception as e:
            print(f"Batch ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ (Chunk: {[uid for uid, _ in chunk]}): {e}")
            for uid, _ in chunk:
                final_result[uid] = []

    return final_result


# --- âœ¨ [ì¶”ê°€] ì—”ë“œí¬ì¸íŠ¸: ì¸ì‚¬ì´ë™ í¬ë§ ì—¬ë¶€ ë¶„ì„ ---
@app.post("/analyze-transfer-intent")
async def analyze_transfer_intent(payload: InterviewDataIn):
    transfer_keywords = ['ì´ë™', 'ë³€ê²½']
    hopefuls = []
    others = []
    try:
        for row in payload.data:
            # ğŸ’¡ ì•„ë˜ ì»¬ëŸ¼ëª…ì€ ì‹¤ì œ ë°ì´í„°ì— ë§ê²Œ í™•ì¸/ìˆ˜ì •í•´ì•¼ í•©ë‹ˆë‹¤.
            opinion_text = row.get('(2) ì„±ì¥/ì—­ëŸ‰/ì»¤ë¦¬ì–´-êµ¬ì„±ì› ì˜ê²¬', '')
            if opinion_text and any(keyword in opinion_text for keyword in transfer_keywords):
                hopefuls.append(row)
            else:
                others.append(row)
        return {
            "transfer_hopefuls": hopefuls,
            "others": others
        }
    except Exception as e:
        print(f"ğŸ’¥ ì¸ì‚¬ì´ë™ ë¶„ì„ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=f"ì¸ì‚¬ì´ë™ í¬ë§ ì—¬ë¶€ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")


# --- ì—”ë“œí¬ì¸íŠ¸ 5: GPT ê¸°ë°˜ HR ì¶”ì²œì•ˆ ìƒì„± (ë³€ê²½ ì—†ìŒ) ---
@app.post("/generate-suggestion")
async def generate_suggestion(data: TextIn):
    if not openai_client:
        raise HTTPException(status_code=500, detail="OpenAI í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    system_prompt = """
ë‹¹ì‹ ì€ SKì—”ë¬´ë¸Œ(SK enmove)ì˜ HR ì „ë¬¸ ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤. ë‹¹ì‹ ì˜ ì—­í• ì€ êµ¬ì„±ì›ì˜ ì˜ê²¬ì„ ë¶„ì„í•˜ì—¬, HR ë‹´ë‹¹ìê°€ ì¦‰ì‹œ ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” êµ¬ì²´ì ì¸ ê°œì„  ë°©ì•ˆì„ ì œì•ˆí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.
ì œì•ˆì€ ë°˜ë“œì‹œ ì•„ë˜ì— ëª…ì‹œëœ 'SKì—”ë¬´ë¸Œ êµ¬ì„±ì› ì„±ì¥ì§€ì› í”„ë¡œê·¸ë¨'ì„ ê¸°ë°˜ìœ¼ë¡œ í•´ì•¼ í•©ë‹ˆë‹¤.
--- SKì—”ë¬´ë¸Œ êµ¬ì„±ì› ì„±ì¥ì§€ì› í”„ë¡œê·¸ë¨ ---
1. ì¼ì„ í†µí•œ ì„±ì¥ (ê²½í—˜)
   - ìê¸° ì£¼ë„ì  Career ì„¤ê³„ ë° ì‹¤í–‰ ì§€ì›
   - TF ë“±ì„ í†µí•œ í•„ìš”í•œ ì „ë¬¸ì„±ì˜ ììœ ë¡œìš´ í™œìš©/ìœ¡ì„±
2. ì—­í• ì„ í†µí•œ ì„±ì¥
   - ë¦¬ë”ë¡œ ì„±ì¥ì„ ìœ„í•œ ì„ ì œì ì´ê³  ì²´ê³„ì ì¸ ìœ¡ì„± í”„ë¡œê·¸ë¨ ì°¸ì—¬
   - ë¦¬ë”ì‹­ ê°œë°œ ë° ì¡°ì§ê°œë°œ í”„ë¡œê·¸ë¨ ì§€ì›
3. í•™ìŠµì„ í†µí•œ ì„±ì¥
   - ë¯¸ë˜ í•„ìš” ì—­ëŸ‰ ë° ê³µí†µì—­ëŸ‰ ê°•í™” ì§€ì›
   - ì¤‘ì¥ê¸° Biz ìˆ˜í–‰ ì—­ëŸ‰ ê°œë°œ ë° ì „ë¬¸ì„± ê°•í™” ì§€ì› (ì—°ìˆ˜ í”„ë¡œê·¸ë¨ ë“±)
   - Global ì—­ëŸ‰ ê°œë°œ ì§€ì›
4. ì—­ëŸ‰ ë°œíœ˜ í™˜ê²½ ì§€ì›
   - êµ¬ì„±ì› Mental Care (êµ¬ì„±ì› ì‹¬ë¦¬ ìƒë‹´, Newcomer Counseling ë“±)
   - êµ¬ì„±ì› Physical Care (ì‚¬ë‚´ í—¬ìŠ¤ íŠ¸ë ˆì´ë‹ ì§€ì› ë“±)
---
ì§€ì‹œì‚¬í•­: ì•„ë˜ êµ¬ì„±ì›ì˜ ì˜ê²¬ì„ ë°”íƒ•ìœ¼ë¡œ, ìœ„ í”„ë¡œê·¸ë¨ ì¤‘ ê°€ì¥ ì í•©í•œ í•´ê²°ì±…ì„ ì°¾ì•„ êµ¬ì²´ì ì¸ ì‹¤í–‰ ë°©ì•ˆì„ **í•œêµ­ì–´ í•œ ë¬¸ì¥**ìœ¼ë¡œ ì œì•ˆí•˜ì„¸ìš”.
ì¶œë ¥ ì˜ˆì‹œ: "ìƒˆë¡œìš´ í”„ë¡œì íŠ¸ ë¦¬ë”© ê²½í—˜ì„ ìŒ“ê³  ì‹¶ë‹¤ëŠ” ì˜ê²¬ì— ë”°ë¼, ìœ ê´€ ë¶€ì„œì˜ ì‹ ê·œ TFì— ì°¸ì—¬í•˜ì—¬ ì „ë¬¸ì„±ì„ í™œìš©í•˜ê³  ë¦¬ë”ì‹­ì„ í‚¤ìš¸ ê¸°íšŒë¥¼ ì œê³µí•˜ëŠ” ê²ƒì„ ê³ ë ¤í•´ë³¼ ìˆ˜
ìˆê² ìŠµë‹ˆë‹¤."
"""
    user_prompt = f"ë‹¤ìŒ SKì—”ë¬´ë¸Œ êµ¬ì„±ì›ì˜ ì˜ê²¬ì— ëŒ€í•œ ë§ì¶¤í˜• HR ì¶”ì²œì•ˆì„ ì§€ì‹œì‚¬í•­ì— ë§ê²Œ í•œ ë¬¸ì¥ìœ¼ë¡œ ë§Œë“¤ì–´ì£¼ì„¸ìš”:\n\n{data.text}"

    try:
        response = openai_client.chat.completions.create(
            model=GPT_MODEL_NAME,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.7,
        )
        suggestion = response.choices[0].message.content.strip()

        if not suggestion:
            return {"suggestion": "AI ì¶”ì²œì•ˆì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}

        return {"suggestion": suggestion}

    except openai.APIError as e:
        raise HTTPException(status_code=503, detail=f"OpenAI API í˜¸ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}")
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì¶”ì²œì•ˆ ìƒì„± ì¤‘ ì„œë²„ ì˜¤ë¥˜ ë°œìƒ: {e}")


@app.get("/")
def read_root():
    return {"message": "HR ë©´ë‹´ ë¶„ì„ API, 3ê°œ ì—”ë“œí¬ì¸íŠ¸ ì‹¤í–‰ ì¤‘"}

# uvicorn ì„œë²„ ì‹¤í–‰ (ë¡œì»¬ í…ŒìŠ¤íŠ¸ìš©)
if __name__ == "__main__":
    uvicorn.run(app, host="127.0.0.1", port=8000)