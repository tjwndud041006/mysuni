{"ast":null,"code":"/*\nCopyright (c) 2011, Rob Ellis, Chris Umbel\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n*/\n\nconst _ = require('underscore');\nconst Tokenizer = require('../tokenizers/regexp_tokenizer').WordTokenizer;\nlet tokenizer = new Tokenizer();\nlet stopwords = require('../util/stopwords').words;\nconst fs = require('fs');\n\n// Returns a frequency map of word to frequency\n// Key is the document key and stored in the map that is returned as __keys\nfunction buildDocument(text, key) {\n  let stopOut;\n  if (typeof text === 'string') {\n    text = tokenizer.tokenize(text.toLowerCase());\n    stopOut = true;\n  } else if (!_.isArray(text)) {\n    stopOut = false;\n    return text;\n  }\n  return text.reduce(function (document, term) {\n    // next line solves https://github.com/NaturalNode/natural/issues/119\n    if (typeof document[term] === 'function') {\n      document[term] = 0;\n    }\n    if (!stopOut || stopwords.indexOf(term) < 0) {\n      document[term] = document[term] ? document[term] + 1 : 1;\n    }\n    return document;\n  }, {\n    __key: key\n  });\n}\nfunction documentHasTerm(term, document) {\n  return document[term] && document[term] > 0;\n}\n\n// backwards compatibility for < node 0.10\nfunction isEncoding(encoding) {\n  if (typeof Buffer.isEncoding !== 'undefined') {\n    return Buffer.isEncoding(encoding);\n  }\n  switch ((encoding + '').toLowerCase()) {\n    case 'hex':\n    case 'utf8':\n    case 'utf-8':\n    case 'ascii':\n    case 'binary':\n    case 'base64':\n    case 'ucs2':\n    case 'ucs-2':\n    case 'utf16le':\n    case 'utf-16le':\n    case 'raw':\n      return true;\n  }\n  return false;\n}\nclass TfIdf {\n  constructor(deserialized) {\n    if (deserialized) {\n      this.documents = deserialized.documents;\n    } else {\n      this.documents = [];\n    }\n    this._idfCache = {};\n  }\n  static tf(term, document) {\n    return document[term] ? document[term] : 0;\n  }\n\n  // Returns the inverse document frequency of the term\n  // If force is true the cache will be invalidated and recomputed\n  idf(term, force) {\n    // Lookup the term in the New term-IDF caching,\n    // this will cut search times down exponentially on large document sets.\n    // if (this._idfCache[term] && this._idfCache.hasOwnProperty(term) && force !== true) { return this._idfCache[term] }\n    if (this._idfCache[term] && force !== true) {\n      return this._idfCache[term];\n    }\n\n    // Count the number of documents that contain the term\n    const docsWithTerm = this.documents.reduce(function (count, document) {\n      return count + (documentHasTerm(term, document) ? 1 : 0);\n    }, 0);\n\n    // Compute the inverse document frequency\n    const idf = 1 + Math.log(this.documents.length / (1 + docsWithTerm));\n\n    // Add the idf to the term cache and return it\n    this._idfCache[term] = idf;\n    return idf;\n  }\n\n  // If restoreCache is set to true, all terms idf scores currently cached will be recomputed.\n  // Otherwise, the cache will just be wiped clean\n  addDocument(document, key, restoreCache) {\n    this.documents.push(buildDocument(document, key));\n\n    // make sure the cache is invalidated when new documents arrive\n    if (restoreCache === true) {\n      for (const term in this._idfCache) {\n        // invoking idf with the force option set will\n        // force a recomputation of the idf, and it will\n        // automatically refresh the cache value.\n        this.idf(term, true);\n      }\n    } else {\n      // this._idfCache = {}\n      // so that we do not have trouble with terms that match property names\n      this._idfCache = Object.create(null);\n    }\n  }\n\n  // Remove a document from the corpus\n  // Returns true if the document was found\n  // Returns false if the document was not found\n  removeDocument(key) {\n    // Find the document\n    const index = this.documents.findIndex(function (document) {\n      return document.__key === key;\n    });\n    // If found, remove it\n    if (index > -1) {\n      this.documents.splice(index, 1);\n      // Invalidate the cache\n      this._idfCache = Object.create(null);\n      return true;\n    }\n    return false;\n  }\n\n  // If restoreCache is set to true, all terms idf scores currently cached will be recomputed.\n  // Otherwise, the cache will just be wiped clean\n  addFileSync(path, encoding, key, restoreCache) {\n    if (!encoding) {\n      encoding = 'utf8';\n    }\n    if (!isEncoding(encoding)) {\n      throw new Error('Invalid encoding: ' + encoding);\n    }\n    const document = fs.readFileSync(path, encoding);\n    this.documents.push(buildDocument(document, key));\n\n    // make sure the cache is invalidated when new documents arrive\n    if (restoreCache === true) {\n      for (const term in this._idfCache) {\n        // invoking idf with the force option set will\n        // force a recomputation of the idf, and it will\n        // automatically refresh the cache value.\n        this.idf(term, true);\n      }\n    } else {\n      this._idfCache = {};\n    }\n  }\n  tfidf(terms, d) {\n    const _this = this;\n    if (!_.isArray(terms)) {\n      terms = tokenizer.tokenize(terms.toString().toLowerCase());\n    }\n    return terms.reduce(function (value, term) {\n      let idf = _this.idf(term);\n      idf = idf === Infinity ? 0 : idf;\n      return value + TfIdf.tf(term, _this.documents[d]) * idf;\n    }, 0.0);\n  }\n  listTerms(d) {\n    const terms = [];\n    const _this = this;\n    for (const term in this.documents[d]) {\n      if (this.documents[d]) {\n        if (term !== '__key') {\n          terms.push({\n            term,\n            tf: TfIdf.tf(term, _this.documents[d]),\n            idf: _this.idf(term),\n            tfidf: _this.tfidf([term], d)\n          });\n        }\n      }\n    }\n    return terms.sort(function (x, y) {\n      return y.tfidf - x.tfidf;\n    });\n  }\n  tfidfs(terms, callback) {\n    const tfidfs = new Array(this.documents.length);\n    for (let i = 0; i < this.documents.length; i++) {\n      tfidfs[i] = this.tfidf(terms, i);\n      if (callback) {\n        callback(i, tfidfs[i], this.documents[i].__key);\n      }\n    }\n    return tfidfs;\n  }\n\n  // Define a tokenizer other than the default \"WordTokenizer\"\n  setTokenizer(t) {\n    if (!_.isFunction(t.tokenize)) {\n      throw new Error('Expected a valid Tokenizer');\n    }\n    tokenizer = t;\n  }\n\n  // Define a stopwords other than the default\n  setStopwords(customStopwords) {\n    if (!Array.isArray(customStopwords)) {\n      return false;\n    }\n    let wrongElement = false;\n    customStopwords.forEach(stopword => {\n      if (typeof stopword !== 'string') {\n        wrongElement = true;\n      }\n    });\n    if (wrongElement) {\n      return false;\n    }\n    stopwords = customStopwords;\n    return true;\n  }\n}\nmodule.exports = TfIdf;","map":{"version":3,"names":["_","require","Tokenizer","WordTokenizer","tokenizer","stopwords","words","fs","buildDocument","text","key","stopOut","tokenize","toLowerCase","isArray","reduce","document","term","indexOf","__key","documentHasTerm","isEncoding","encoding","Buffer","TfIdf","constructor","deserialized","documents","_idfCache","tf","idf","force","docsWithTerm","count","Math","log","length","addDocument","restoreCache","push","Object","create","removeDocument","index","findIndex","splice","addFileSync","path","Error","readFileSync","tfidf","terms","d","_this","toString","value","Infinity","listTerms","sort","x","y","tfidfs","callback","Array","i","setTokenizer","t","isFunction","setStopwords","customStopwords","wrongElement","forEach","stopword","module","exports"],"sources":["/Users/seojuyoung/sunic/project/frontend/node_modules/natural/lib/natural/tfidf/tfidf.js"],"sourcesContent":["/*\nCopyright (c) 2011, Rob Ellis, Chris Umbel\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n*/\n\nconst _ = require('underscore')\nconst Tokenizer = require('../tokenizers/regexp_tokenizer').WordTokenizer\nlet tokenizer = new Tokenizer()\nlet stopwords = require('../util/stopwords').words\nconst fs = require('fs')\n\n// Returns a frequency map of word to frequency\n// Key is the document key and stored in the map that is returned as __keys\nfunction buildDocument (text, key) {\n  let stopOut\n\n  if (typeof text === 'string') {\n    text = tokenizer.tokenize(text.toLowerCase())\n    stopOut = true\n  } else if (!_.isArray(text)) {\n    stopOut = false\n    return text\n  }\n\n  return text.reduce(function (document, term) {\n    // next line solves https://github.com/NaturalNode/natural/issues/119\n    if (typeof document[term] === 'function') {\n      document[term] = 0\n    }\n    if (!stopOut || stopwords.indexOf(term) < 0) {\n      document[term] = (document[term] ? document[term] + 1 : 1)\n    }\n    return document\n  }, { __key: key })\n}\n\nfunction documentHasTerm (term, document) {\n  return document[term] && document[term] > 0\n}\n\n// backwards compatibility for < node 0.10\nfunction isEncoding (encoding) {\n  if (typeof Buffer.isEncoding !== 'undefined') { return Buffer.isEncoding(encoding) }\n  switch ((encoding + '').toLowerCase()) {\n    case 'hex':\n    case 'utf8':\n    case 'utf-8':\n    case 'ascii':\n    case 'binary':\n    case 'base64':\n    case 'ucs2':\n    case 'ucs-2':\n    case 'utf16le':\n    case 'utf-16le':\n    case 'raw':\n      return true\n  }\n  return false\n}\n\nclass TfIdf {\n  constructor (deserialized) {\n    if (deserialized) {\n      this.documents = deserialized.documents\n    } else {\n      this.documents = []\n    }\n    this._idfCache = {}\n  }\n\n  static tf (term, document) {\n    return document[term] ? document[term] : 0\n  }\n\n  // Returns the inverse document frequency of the term\n  // If force is true the cache will be invalidated and recomputed\n  idf (term, force) {\n    // Lookup the term in the New term-IDF caching,\n    // this will cut search times down exponentially on large document sets.\n    // if (this._idfCache[term] && this._idfCache.hasOwnProperty(term) && force !== true) { return this._idfCache[term] }\n    if (this._idfCache[term] && force !== true) {\n      return this._idfCache[term]\n    }\n\n    // Count the number of documents that contain the term\n    const docsWithTerm = this.documents.reduce(function (count, document) {\n      return count + (documentHasTerm(term, document) ? 1 : 0)\n    }, 0)\n\n    // Compute the inverse document frequency\n    const idf = 1 + Math.log((this.documents.length) / (1 + docsWithTerm))\n\n    // Add the idf to the term cache and return it\n    this._idfCache[term] = idf\n    return idf\n  }\n\n  // If restoreCache is set to true, all terms idf scores currently cached will be recomputed.\n  // Otherwise, the cache will just be wiped clean\n  addDocument (document, key, restoreCache) {\n    this.documents.push(buildDocument(document, key))\n\n    // make sure the cache is invalidated when new documents arrive\n    if (restoreCache === true) {\n      for (const term in this._idfCache) {\n        // invoking idf with the force option set will\n        // force a recomputation of the idf, and it will\n        // automatically refresh the cache value.\n        this.idf(term, true)\n      }\n    } else {\n      // this._idfCache = {}\n      // so that we do not have trouble with terms that match property names\n      this._idfCache = Object.create(null)\n    }\n  }\n\n  // Remove a document from the corpus\n  // Returns true if the document was found\n  // Returns false if the document was not found\n  removeDocument (key) {\n    // Find the document\n    const index = this.documents.findIndex(function (document) {\n      return document.__key === key\n    })\n    // If found, remove it\n    if (index > -1) {\n      this.documents.splice(index, 1)\n      // Invalidate the cache\n      this._idfCache = Object.create(null)\n      return true\n    }\n\n    return false\n  }\n\n  // If restoreCache is set to true, all terms idf scores currently cached will be recomputed.\n  // Otherwise, the cache will just be wiped clean\n  addFileSync (path, encoding, key, restoreCache) {\n    if (!encoding) { encoding = 'utf8' }\n    if (!isEncoding(encoding)) { throw new Error('Invalid encoding: ' + encoding) }\n\n    const document = fs.readFileSync(path, encoding)\n    this.documents.push(buildDocument(document, key))\n\n    // make sure the cache is invalidated when new documents arrive\n    if (restoreCache === true) {\n      for (const term in this._idfCache) {\n        // invoking idf with the force option set will\n        // force a recomputation of the idf, and it will\n        // automatically refresh the cache value.\n        this.idf(term, true)\n      }\n    } else {\n      this._idfCache = {}\n    }\n  }\n\n  tfidf (terms, d) {\n    const _this = this\n\n    if (!_.isArray(terms)) {\n      terms = tokenizer.tokenize(terms.toString().toLowerCase())\n    }\n\n    return terms.reduce(function (value, term) {\n      let idf = _this.idf(term)\n      idf = idf === Infinity ? 0 : idf\n      return value + (TfIdf.tf(term, _this.documents[d]) * idf)\n    }, 0.0)\n  }\n\n  listTerms (d) {\n    const terms = []\n    const _this = this\n    for (const term in this.documents[d]) {\n      if (this.documents[d]) {\n        if (term !== '__key') {\n          terms.push({\n            term,\n            tf: TfIdf.tf(term, _this.documents[d]),\n            idf: _this.idf(term),\n            tfidf: _this.tfidf([term], d)\n          })\n        }\n      }\n    }\n\n    return terms.sort(function (x, y) { return y.tfidf - x.tfidf })\n  }\n\n  tfidfs (terms, callback) {\n    const tfidfs = new Array(this.documents.length)\n\n    for (let i = 0; i < this.documents.length; i++) {\n      tfidfs[i] = this.tfidf(terms, i)\n\n      if (callback) { callback(i, tfidfs[i], this.documents[i].__key) }\n    }\n\n    return tfidfs\n  }\n\n  // Define a tokenizer other than the default \"WordTokenizer\"\n  setTokenizer (t) {\n    if (!_.isFunction(t.tokenize)) { throw new Error('Expected a valid Tokenizer') }\n    tokenizer = t\n  }\n\n  // Define a stopwords other than the default\n  setStopwords (customStopwords) {\n    if (!Array.isArray(customStopwords)) { return false }\n\n    let wrongElement = false\n    customStopwords.forEach(stopword => {\n      if ((typeof stopword) !== 'string') {\n        wrongElement = true\n      }\n    })\n    if (wrongElement) {\n      return false\n    }\n\n    stopwords = customStopwords\n    return true\n  }\n}\n\nmodule.exports = TfIdf\n"],"mappings":"AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,MAAMA,CAAC,GAAGC,OAAO,CAAC,YAAY,CAAC;AAC/B,MAAMC,SAAS,GAAGD,OAAO,CAAC,gCAAgC,CAAC,CAACE,aAAa;AACzE,IAAIC,SAAS,GAAG,IAAIF,SAAS,CAAC,CAAC;AAC/B,IAAIG,SAAS,GAAGJ,OAAO,CAAC,mBAAmB,CAAC,CAACK,KAAK;AAClD,MAAMC,EAAE,GAAGN,OAAO,CAAC,IAAI,CAAC;;AAExB;AACA;AACA,SAASO,aAAaA,CAAEC,IAAI,EAAEC,GAAG,EAAE;EACjC,IAAIC,OAAO;EAEX,IAAI,OAAOF,IAAI,KAAK,QAAQ,EAAE;IAC5BA,IAAI,GAAGL,SAAS,CAACQ,QAAQ,CAACH,IAAI,CAACI,WAAW,CAAC,CAAC,CAAC;IAC7CF,OAAO,GAAG,IAAI;EAChB,CAAC,MAAM,IAAI,CAACX,CAAC,CAACc,OAAO,CAACL,IAAI,CAAC,EAAE;IAC3BE,OAAO,GAAG,KAAK;IACf,OAAOF,IAAI;EACb;EAEA,OAAOA,IAAI,CAACM,MAAM,CAAC,UAAUC,QAAQ,EAAEC,IAAI,EAAE;IAC3C;IACA,IAAI,OAAOD,QAAQ,CAACC,IAAI,CAAC,KAAK,UAAU,EAAE;MACxCD,QAAQ,CAACC,IAAI,CAAC,GAAG,CAAC;IACpB;IACA,IAAI,CAACN,OAAO,IAAIN,SAAS,CAACa,OAAO,CAACD,IAAI,CAAC,GAAG,CAAC,EAAE;MAC3CD,QAAQ,CAACC,IAAI,CAAC,GAAID,QAAQ,CAACC,IAAI,CAAC,GAAGD,QAAQ,CAACC,IAAI,CAAC,GAAG,CAAC,GAAG,CAAE;IAC5D;IACA,OAAOD,QAAQ;EACjB,CAAC,EAAE;IAAEG,KAAK,EAAET;EAAI,CAAC,CAAC;AACpB;AAEA,SAASU,eAAeA,CAAEH,IAAI,EAAED,QAAQ,EAAE;EACxC,OAAOA,QAAQ,CAACC,IAAI,CAAC,IAAID,QAAQ,CAACC,IAAI,CAAC,GAAG,CAAC;AAC7C;;AAEA;AACA,SAASI,UAAUA,CAAEC,QAAQ,EAAE;EAC7B,IAAI,OAAOC,MAAM,CAACF,UAAU,KAAK,WAAW,EAAE;IAAE,OAAOE,MAAM,CAACF,UAAU,CAACC,QAAQ,CAAC;EAAC;EACnF,QAAQ,CAACA,QAAQ,GAAG,EAAE,EAAET,WAAW,CAAC,CAAC;IACnC,KAAK,KAAK;IACV,KAAK,MAAM;IACX,KAAK,OAAO;IACZ,KAAK,OAAO;IACZ,KAAK,QAAQ;IACb,KAAK,QAAQ;IACb,KAAK,MAAM;IACX,KAAK,OAAO;IACZ,KAAK,SAAS;IACd,KAAK,UAAU;IACf,KAAK,KAAK;MACR,OAAO,IAAI;EACf;EACA,OAAO,KAAK;AACd;AAEA,MAAMW,KAAK,CAAC;EACVC,WAAWA,CAAEC,YAAY,EAAE;IACzB,IAAIA,YAAY,EAAE;MAChB,IAAI,CAACC,SAAS,GAAGD,YAAY,CAACC,SAAS;IACzC,CAAC,MAAM;MACL,IAAI,CAACA,SAAS,GAAG,EAAE;IACrB;IACA,IAAI,CAACC,SAAS,GAAG,CAAC,CAAC;EACrB;EAEA,OAAOC,EAAEA,CAAEZ,IAAI,EAAED,QAAQ,EAAE;IACzB,OAAOA,QAAQ,CAACC,IAAI,CAAC,GAAGD,QAAQ,CAACC,IAAI,CAAC,GAAG,CAAC;EAC5C;;EAEA;EACA;EACAa,GAAGA,CAAEb,IAAI,EAAEc,KAAK,EAAE;IAChB;IACA;IACA;IACA,IAAI,IAAI,CAACH,SAAS,CAACX,IAAI,CAAC,IAAIc,KAAK,KAAK,IAAI,EAAE;MAC1C,OAAO,IAAI,CAACH,SAAS,CAACX,IAAI,CAAC;IAC7B;;IAEA;IACA,MAAMe,YAAY,GAAG,IAAI,CAACL,SAAS,CAACZ,MAAM,CAAC,UAAUkB,KAAK,EAAEjB,QAAQ,EAAE;MACpE,OAAOiB,KAAK,IAAIb,eAAe,CAACH,IAAI,EAAED,QAAQ,CAAC,GAAG,CAAC,GAAG,CAAC,CAAC;IAC1D,CAAC,EAAE,CAAC,CAAC;;IAEL;IACA,MAAMc,GAAG,GAAG,CAAC,GAAGI,IAAI,CAACC,GAAG,CAAE,IAAI,CAACR,SAAS,CAACS,MAAM,IAAK,CAAC,GAAGJ,YAAY,CAAC,CAAC;;IAEtE;IACA,IAAI,CAACJ,SAAS,CAACX,IAAI,CAAC,GAAGa,GAAG;IAC1B,OAAOA,GAAG;EACZ;;EAEA;EACA;EACAO,WAAWA,CAAErB,QAAQ,EAAEN,GAAG,EAAE4B,YAAY,EAAE;IACxC,IAAI,CAACX,SAAS,CAACY,IAAI,CAAC/B,aAAa,CAACQ,QAAQ,EAAEN,GAAG,CAAC,CAAC;;IAEjD;IACA,IAAI4B,YAAY,KAAK,IAAI,EAAE;MACzB,KAAK,MAAMrB,IAAI,IAAI,IAAI,CAACW,SAAS,EAAE;QACjC;QACA;QACA;QACA,IAAI,CAACE,GAAG,CAACb,IAAI,EAAE,IAAI,CAAC;MACtB;IACF,CAAC,MAAM;MACL;MACA;MACA,IAAI,CAACW,SAAS,GAAGY,MAAM,CAACC,MAAM,CAAC,IAAI,CAAC;IACtC;EACF;;EAEA;EACA;EACA;EACAC,cAAcA,CAAEhC,GAAG,EAAE;IACnB;IACA,MAAMiC,KAAK,GAAG,IAAI,CAAChB,SAAS,CAACiB,SAAS,CAAC,UAAU5B,QAAQ,EAAE;MACzD,OAAOA,QAAQ,CAACG,KAAK,KAAKT,GAAG;IAC/B,CAAC,CAAC;IACF;IACA,IAAIiC,KAAK,GAAG,CAAC,CAAC,EAAE;MACd,IAAI,CAAChB,SAAS,CAACkB,MAAM,CAACF,KAAK,EAAE,CAAC,CAAC;MAC/B;MACA,IAAI,CAACf,SAAS,GAAGY,MAAM,CAACC,MAAM,CAAC,IAAI,CAAC;MACpC,OAAO,IAAI;IACb;IAEA,OAAO,KAAK;EACd;;EAEA;EACA;EACAK,WAAWA,CAAEC,IAAI,EAAEzB,QAAQ,EAAEZ,GAAG,EAAE4B,YAAY,EAAE;IAC9C,IAAI,CAAChB,QAAQ,EAAE;MAAEA,QAAQ,GAAG,MAAM;IAAC;IACnC,IAAI,CAACD,UAAU,CAACC,QAAQ,CAAC,EAAE;MAAE,MAAM,IAAI0B,KAAK,CAAC,oBAAoB,GAAG1B,QAAQ,CAAC;IAAC;IAE9E,MAAMN,QAAQ,GAAGT,EAAE,CAAC0C,YAAY,CAACF,IAAI,EAAEzB,QAAQ,CAAC;IAChD,IAAI,CAACK,SAAS,CAACY,IAAI,CAAC/B,aAAa,CAACQ,QAAQ,EAAEN,GAAG,CAAC,CAAC;;IAEjD;IACA,IAAI4B,YAAY,KAAK,IAAI,EAAE;MACzB,KAAK,MAAMrB,IAAI,IAAI,IAAI,CAACW,SAAS,EAAE;QACjC;QACA;QACA;QACA,IAAI,CAACE,GAAG,CAACb,IAAI,EAAE,IAAI,CAAC;MACtB;IACF,CAAC,MAAM;MACL,IAAI,CAACW,SAAS,GAAG,CAAC,CAAC;IACrB;EACF;EAEAsB,KAAKA,CAAEC,KAAK,EAAEC,CAAC,EAAE;IACf,MAAMC,KAAK,GAAG,IAAI;IAElB,IAAI,CAACrD,CAAC,CAACc,OAAO,CAACqC,KAAK,CAAC,EAAE;MACrBA,KAAK,GAAG/C,SAAS,CAACQ,QAAQ,CAACuC,KAAK,CAACG,QAAQ,CAAC,CAAC,CAACzC,WAAW,CAAC,CAAC,CAAC;IAC5D;IAEA,OAAOsC,KAAK,CAACpC,MAAM,CAAC,UAAUwC,KAAK,EAAEtC,IAAI,EAAE;MACzC,IAAIa,GAAG,GAAGuB,KAAK,CAACvB,GAAG,CAACb,IAAI,CAAC;MACzBa,GAAG,GAAGA,GAAG,KAAK0B,QAAQ,GAAG,CAAC,GAAG1B,GAAG;MAChC,OAAOyB,KAAK,GAAI/B,KAAK,CAACK,EAAE,CAACZ,IAAI,EAAEoC,KAAK,CAAC1B,SAAS,CAACyB,CAAC,CAAC,CAAC,GAAGtB,GAAI;IAC3D,CAAC,EAAE,GAAG,CAAC;EACT;EAEA2B,SAASA,CAAEL,CAAC,EAAE;IACZ,MAAMD,KAAK,GAAG,EAAE;IAChB,MAAME,KAAK,GAAG,IAAI;IAClB,KAAK,MAAMpC,IAAI,IAAI,IAAI,CAACU,SAAS,CAACyB,CAAC,CAAC,EAAE;MACpC,IAAI,IAAI,CAACzB,SAAS,CAACyB,CAAC,CAAC,EAAE;QACrB,IAAInC,IAAI,KAAK,OAAO,EAAE;UACpBkC,KAAK,CAACZ,IAAI,CAAC;YACTtB,IAAI;YACJY,EAAE,EAAEL,KAAK,CAACK,EAAE,CAACZ,IAAI,EAAEoC,KAAK,CAAC1B,SAAS,CAACyB,CAAC,CAAC,CAAC;YACtCtB,GAAG,EAAEuB,KAAK,CAACvB,GAAG,CAACb,IAAI,CAAC;YACpBiC,KAAK,EAAEG,KAAK,CAACH,KAAK,CAAC,CAACjC,IAAI,CAAC,EAAEmC,CAAC;UAC9B,CAAC,CAAC;QACJ;MACF;IACF;IAEA,OAAOD,KAAK,CAACO,IAAI,CAAC,UAAUC,CAAC,EAAEC,CAAC,EAAE;MAAE,OAAOA,CAAC,CAACV,KAAK,GAAGS,CAAC,CAACT,KAAK;IAAC,CAAC,CAAC;EACjE;EAEAW,MAAMA,CAAEV,KAAK,EAAEW,QAAQ,EAAE;IACvB,MAAMD,MAAM,GAAG,IAAIE,KAAK,CAAC,IAAI,CAACpC,SAAS,CAACS,MAAM,CAAC;IAE/C,KAAK,IAAI4B,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAG,IAAI,CAACrC,SAAS,CAACS,MAAM,EAAE4B,CAAC,EAAE,EAAE;MAC9CH,MAAM,CAACG,CAAC,CAAC,GAAG,IAAI,CAACd,KAAK,CAACC,KAAK,EAAEa,CAAC,CAAC;MAEhC,IAAIF,QAAQ,EAAE;QAAEA,QAAQ,CAACE,CAAC,EAAEH,MAAM,CAACG,CAAC,CAAC,EAAE,IAAI,CAACrC,SAAS,CAACqC,CAAC,CAAC,CAAC7C,KAAK,CAAC;MAAC;IAClE;IAEA,OAAO0C,MAAM;EACf;;EAEA;EACAI,YAAYA,CAAEC,CAAC,EAAE;IACf,IAAI,CAAClE,CAAC,CAACmE,UAAU,CAACD,CAAC,CAACtD,QAAQ,CAAC,EAAE;MAAE,MAAM,IAAIoC,KAAK,CAAC,4BAA4B,CAAC;IAAC;IAC/E5C,SAAS,GAAG8D,CAAC;EACf;;EAEA;EACAE,YAAYA,CAAEC,eAAe,EAAE;IAC7B,IAAI,CAACN,KAAK,CAACjD,OAAO,CAACuD,eAAe,CAAC,EAAE;MAAE,OAAO,KAAK;IAAC;IAEpD,IAAIC,YAAY,GAAG,KAAK;IACxBD,eAAe,CAACE,OAAO,CAACC,QAAQ,IAAI;MAClC,IAAK,OAAOA,QAAQ,KAAM,QAAQ,EAAE;QAClCF,YAAY,GAAG,IAAI;MACrB;IACF,CAAC,CAAC;IACF,IAAIA,YAAY,EAAE;MAChB,OAAO,KAAK;IACd;IAEAjE,SAAS,GAAGgE,eAAe;IAC3B,OAAO,IAAI;EACb;AACF;AAEAI,MAAM,CAACC,OAAO,GAAGlD,KAAK","ignoreList":[]},"metadata":{},"sourceType":"script","externalDependencies":[]}