{"ast":null,"code":"/*\n  Corpus class for parsing and analysing corpora\n  Copyright (C) 2019 Hugo W.L. ter Doest\n\n  This program is free software: you can redistribute it and/or modify\n  it under the terms of the GNU General Public License as published by\n  the Free Software Foundation, either version 3 of the License, or\n  (at your option) any later version.\n\n  This program is distributed in the hope that it will be useful,\n  but WITHOUT ANY WARRANTY; without even the implied warranty of\n  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n  GNU General Public License for more details.\n\n  You should have received a copy of the GNU General Public License\n  along with this program.  If not, see <http://www.gnu.org/licenses/>.\n*/\n\n'use strict';\n\nconst Lexicon = require('./Lexicon');\nconst BROWN = 1;\nconst JSON = 2;\n\n// sentences: an array of annotated sentences\n// A sentence is an array of annotated tokens\n// A token is an object with (token, tag, testTag, ruleList)\nclass Corpus {\n  constructor(data, typeOfCorpus, SentenceClass) {\n    this.wordCount = 0;\n    this.sentences = [];\n    const that = this;\n    if (data) {\n      // For other types of corpora add a case here and supply a parsing method\n      switch (typeOfCorpus) {\n        case BROWN:\n          this.parseBrownCorpus(data, SentenceClass);\n          break;\n        case JSON:\n          // Assume it is a JSON object of a corpus\n          data.sentences.forEach(function (s) {\n            const taggedSentence = new SentenceClass(s.taggedWords);\n            that.sentences.push(taggedSentence);\n            that.wordCount += s.taggedWords.length;\n          });\n          break;\n      }\n    }\n  }\n\n  // data is raw text\n  // A corpus parsing method should split the corpus in sentences each of which\n  // consist of an array of tokens.\n  parseBrownCorpus(data, SentenceClass) {\n    const that = this;\n    const lines = data.split('\\n');\n    lines.forEach(function (line) {\n      const trimmedLine = line.trim();\n      // Only parse lines that contain characters\n      if (trimmedLine !== '') {\n        const taggedSentence = new SentenceClass();\n        const tokens = line.trim().split(/\\s+/);\n        tokens.forEach(function (token) {\n          that.wordCount++;\n          // Create a tagged sentences consisting of tokens\n          const wordPlusTag = token.split('_');\n          taggedSentence.addTaggedWord(wordPlusTag[0], wordPlusTag[1]);\n        });\n\n        // Add the sentence to the corpus\n        that.sentences.push(taggedSentence);\n      }\n    });\n  }\n\n  // Returns an array of all POS tags used in the corpus\n  getTags() {\n    return Object.keys(this.posTags);\n  }\n\n  // Splits the corpus in a training and testing set.\n  // percentageTrain is the size of the training corpus in percent\n  // Returns an array with two elements: training corpus, testing corpus\n  splitInTrainAndTest(percentageTrain) {\n    const corpusTrain = new Corpus();\n    const corpusTest = new Corpus();\n    const p = percentageTrain / 100;\n    this.sentences.forEach(function (sentence, i) {\n      if (Math.random() < p) {\n        corpusTrain.sentences.push(sentence);\n      } else {\n        corpusTest.sentences.push(sentence);\n      }\n    });\n    return [corpusTrain, corpusTest];\n  }\n\n  // Analyses the corpus:\n  // - registers used POS tags\n  // - records the frequency of POS tag for each word\n  analyse() {\n    this.tagFrequencies = {};\n    this.posTags = {};\n    this.wordCount = 0;\n    const that = this;\n    this.sentences.forEach(function (sentence) {\n      sentence.taggedWords.forEach(function (token) {\n        that.wordCount++;\n\n        // Register the tags used in the corpus\n        that.posTags[token.tag] = true;\n\n        // Register the frequency of the tag\n        if (!that.tagFrequencies[token.token]) {\n          that.tagFrequencies[token.token] = {};\n        }\n        if (!that.tagFrequencies[token.token][token.tag]) {\n          that.tagFrequencies[token.token][token.tag] = 0;\n        }\n        that.tagFrequencies[token.token][token.tag]++;\n      });\n    });\n  }\n\n  // Creates a lexicon by taking the most frequently occurring tag of a word\n  // as the right tag\n  buildLexicon() {\n    const lexicon = new Lexicon();\n    const that = this;\n    this.analyse();\n    Object.keys(this.tagFrequencies).forEach(function (token) {\n      const catToFreq = that.tagFrequencies[token];\n      const categories = Object.keys(catToFreq);\n      function compareByFrequency(a, b) {\n        if (catToFreq[a] > catToFreq[b]) {\n          return -1;\n        } else {\n          if (catToFreq[a] < catToFreq[b]) {\n            return 1;\n          } else {\n            return 0;\n          }\n        }\n      }\n      const sortedCategories = categories.sort(compareByFrequency);\n      lexicon.addWord(token, sortedCategories);\n    });\n    return lexicon;\n  }\n  tag(lexicon) {\n    this.sentences.forEach(function (sentence) {\n      sentence.taggedWords.forEach(function (token) {\n        // tagWord returns a list of categories, take the first category\n        token.testTag = lexicon.tagWord(token.token)[0];\n      });\n    });\n  }\n  nrSentences() {\n    return this.sentences.length;\n  }\n  nrWords() {\n    return this.wordCount;\n  }\n  generateFeatures() {\n    let features = [];\n    this.sentences.forEach(function (sentence) {\n      features = sentence.generateFeatures(features);\n    });\n    // console.log(JSON.stringify(features));\n    return features;\n  }\n  prettyPrint() {\n    this.sentences.forEach(function (sentence, index) {\n      // logger.debug(\"sentence no \" + index + \"\\n\" +\n      //  JSON.stringify(sentence, null, 2));\n    });\n  }\n}\nmodule.exports = Corpus;","map":{"version":3,"names":["Lexicon","require","BROWN","JSON","Corpus","constructor","data","typeOfCorpus","SentenceClass","wordCount","sentences","that","parseBrownCorpus","forEach","s","taggedSentence","taggedWords","push","length","lines","split","line","trimmedLine","trim","tokens","token","wordPlusTag","addTaggedWord","getTags","Object","keys","posTags","splitInTrainAndTest","percentageTrain","corpusTrain","corpusTest","p","sentence","i","Math","random","analyse","tagFrequencies","tag","buildLexicon","lexicon","catToFreq","categories","compareByFrequency","a","b","sortedCategories","sort","addWord","testTag","tagWord","nrSentences","nrWords","generateFeatures","features","prettyPrint","index","module","exports"],"sources":["/Users/seojuyoung/sunic/project/frontend/node_modules/natural/lib/natural/brill_pos_tagger/lib/Corpus.js"],"sourcesContent":["/*\n  Corpus class for parsing and analysing corpora\n  Copyright (C) 2019 Hugo W.L. ter Doest\n\n  This program is free software: you can redistribute it and/or modify\n  it under the terms of the GNU General Public License as published by\n  the Free Software Foundation, either version 3 of the License, or\n  (at your option) any later version.\n\n  This program is distributed in the hope that it will be useful,\n  but WITHOUT ANY WARRANTY; without even the implied warranty of\n  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n  GNU General Public License for more details.\n\n  You should have received a copy of the GNU General Public License\n  along with this program.  If not, see <http://www.gnu.org/licenses/>.\n*/\n\n'use strict'\n\nconst Lexicon = require('./Lexicon')\n\nconst BROWN = 1\nconst JSON = 2\n\n// sentences: an array of annotated sentences\n// A sentence is an array of annotated tokens\n// A token is an object with (token, tag, testTag, ruleList)\nclass Corpus {\n  constructor (data, typeOfCorpus, SentenceClass) {\n    this.wordCount = 0\n    this.sentences = []\n    const that = this\n    if (data) {\n      // For other types of corpora add a case here and supply a parsing method\n      switch (typeOfCorpus) {\n        case BROWN:\n          this.parseBrownCorpus(data, SentenceClass)\n          break\n        case JSON:\n          // Assume it is a JSON object of a corpus\n          data.sentences.forEach(function (s) {\n            const taggedSentence = new SentenceClass(s.taggedWords)\n            that.sentences.push(taggedSentence)\n            that.wordCount += s.taggedWords.length\n          })\n          break\n      }\n    }\n  }\n\n  // data is raw text\n  // A corpus parsing method should split the corpus in sentences each of which\n  // consist of an array of tokens.\n  parseBrownCorpus (data, SentenceClass) {\n    const that = this\n\n    const lines = data.split('\\n')\n    lines.forEach(function (line) {\n      const trimmedLine = line.trim()\n      // Only parse lines that contain characters\n      if (trimmedLine !== '') {\n        const taggedSentence = new SentenceClass()\n        const tokens = line.trim().split(/\\s+/)\n        tokens.forEach(function (token) {\n          that.wordCount++\n          // Create a tagged sentences consisting of tokens\n          const wordPlusTag = token.split('_')\n          taggedSentence.addTaggedWord(wordPlusTag[0], wordPlusTag[1])\n        })\n\n        // Add the sentence to the corpus\n        that.sentences.push(taggedSentence)\n      }\n    })\n  }\n\n  // Returns an array of all POS tags used in the corpus\n  getTags () {\n    return Object.keys(this.posTags)\n  }\n\n  // Splits the corpus in a training and testing set.\n  // percentageTrain is the size of the training corpus in percent\n  // Returns an array with two elements: training corpus, testing corpus\n  splitInTrainAndTest (percentageTrain) {\n    const corpusTrain = new Corpus()\n    const corpusTest = new Corpus()\n\n    const p = percentageTrain / 100\n    this.sentences.forEach(function (sentence, i) {\n      if (Math.random() < p) {\n        corpusTrain.sentences.push(sentence)\n      } else {\n        corpusTest.sentences.push(sentence)\n      }\n    })\n    return [corpusTrain, corpusTest]\n  }\n\n  // Analyses the corpus:\n  // - registers used POS tags\n  // - records the frequency of POS tag for each word\n  analyse () {\n    this.tagFrequencies = {}\n    this.posTags = {}\n    this.wordCount = 0\n\n    const that = this\n    this.sentences.forEach(function (sentence) {\n      sentence.taggedWords.forEach(function (token) {\n        that.wordCount++\n\n        // Register the tags used in the corpus\n        that.posTags[token.tag] = true\n\n        // Register the frequency of the tag\n        if (!that.tagFrequencies[token.token]) {\n          that.tagFrequencies[token.token] = {}\n        }\n        if (!that.tagFrequencies[token.token][token.tag]) {\n          that.tagFrequencies[token.token][token.tag] = 0\n        }\n        that.tagFrequencies[token.token][token.tag]++\n      })\n    })\n  }\n\n  // Creates a lexicon by taking the most frequently occurring tag of a word\n  // as the right tag\n  buildLexicon () {\n    const lexicon = new Lexicon()\n    const that = this\n\n    this.analyse()\n    Object.keys(this.tagFrequencies).forEach(function (token) {\n      const catToFreq = that.tagFrequencies[token]\n      const categories = Object.keys(catToFreq)\n\n      function compareByFrequency (a, b) {\n        if (catToFreq[a] > catToFreq[b]) {\n          return -1\n        } else {\n          if (catToFreq[a] < catToFreq[b]) {\n            return 1\n          } else {\n            return 0\n          }\n        }\n      }\n\n      const sortedCategories = categories.sort(compareByFrequency)\n      lexicon.addWord(token, sortedCategories)\n    })\n    return lexicon\n  }\n\n  tag (lexicon) {\n    this.sentences.forEach(function (sentence) {\n      sentence.taggedWords.forEach(function (token) {\n        // tagWord returns a list of categories, take the first category\n        token.testTag = lexicon.tagWord(token.token)[0]\n      })\n    })\n  }\n\n  nrSentences () {\n    return this.sentences.length\n  }\n\n  nrWords () {\n    return this.wordCount\n  }\n\n  generateFeatures () {\n    let features = []\n    this.sentences.forEach(function (sentence) {\n      features = sentence.generateFeatures(features)\n    })\n    // console.log(JSON.stringify(features));\n    return features\n  }\n\n  prettyPrint () {\n    this.sentences.forEach(function (sentence, index) {\n      // logger.debug(\"sentence no \" + index + \"\\n\" +\n      //  JSON.stringify(sentence, null, 2));\n    })\n  }\n}\n\nmodule.exports = Corpus\n"],"mappings":"AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA,YAAY;;AAEZ,MAAMA,OAAO,GAAGC,OAAO,CAAC,WAAW,CAAC;AAEpC,MAAMC,KAAK,GAAG,CAAC;AACf,MAAMC,IAAI,GAAG,CAAC;;AAEd;AACA;AACA;AACA,MAAMC,MAAM,CAAC;EACXC,WAAWA,CAAEC,IAAI,EAAEC,YAAY,EAAEC,aAAa,EAAE;IAC9C,IAAI,CAACC,SAAS,GAAG,CAAC;IAClB,IAAI,CAACC,SAAS,GAAG,EAAE;IACnB,MAAMC,IAAI,GAAG,IAAI;IACjB,IAAIL,IAAI,EAAE;MACR;MACA,QAAQC,YAAY;QAClB,KAAKL,KAAK;UACR,IAAI,CAACU,gBAAgB,CAACN,IAAI,EAAEE,aAAa,CAAC;UAC1C;QACF,KAAKL,IAAI;UACP;UACAG,IAAI,CAACI,SAAS,CAACG,OAAO,CAAC,UAAUC,CAAC,EAAE;YAClC,MAAMC,cAAc,GAAG,IAAIP,aAAa,CAACM,CAAC,CAACE,WAAW,CAAC;YACvDL,IAAI,CAACD,SAAS,CAACO,IAAI,CAACF,cAAc,CAAC;YACnCJ,IAAI,CAACF,SAAS,IAAIK,CAAC,CAACE,WAAW,CAACE,MAAM;UACxC,CAAC,CAAC;UACF;MACJ;IACF;EACF;;EAEA;EACA;EACA;EACAN,gBAAgBA,CAAEN,IAAI,EAAEE,aAAa,EAAE;IACrC,MAAMG,IAAI,GAAG,IAAI;IAEjB,MAAMQ,KAAK,GAAGb,IAAI,CAACc,KAAK,CAAC,IAAI,CAAC;IAC9BD,KAAK,CAACN,OAAO,CAAC,UAAUQ,IAAI,EAAE;MAC5B,MAAMC,WAAW,GAAGD,IAAI,CAACE,IAAI,CAAC,CAAC;MAC/B;MACA,IAAID,WAAW,KAAK,EAAE,EAAE;QACtB,MAAMP,cAAc,GAAG,IAAIP,aAAa,CAAC,CAAC;QAC1C,MAAMgB,MAAM,GAAGH,IAAI,CAACE,IAAI,CAAC,CAAC,CAACH,KAAK,CAAC,KAAK,CAAC;QACvCI,MAAM,CAACX,OAAO,CAAC,UAAUY,KAAK,EAAE;UAC9Bd,IAAI,CAACF,SAAS,EAAE;UAChB;UACA,MAAMiB,WAAW,GAAGD,KAAK,CAACL,KAAK,CAAC,GAAG,CAAC;UACpCL,cAAc,CAACY,aAAa,CAACD,WAAW,CAAC,CAAC,CAAC,EAAEA,WAAW,CAAC,CAAC,CAAC,CAAC;QAC9D,CAAC,CAAC;;QAEF;QACAf,IAAI,CAACD,SAAS,CAACO,IAAI,CAACF,cAAc,CAAC;MACrC;IACF,CAAC,CAAC;EACJ;;EAEA;EACAa,OAAOA,CAAA,EAAI;IACT,OAAOC,MAAM,CAACC,IAAI,CAAC,IAAI,CAACC,OAAO,CAAC;EAClC;;EAEA;EACA;EACA;EACAC,mBAAmBA,CAAEC,eAAe,EAAE;IACpC,MAAMC,WAAW,GAAG,IAAI9B,MAAM,CAAC,CAAC;IAChC,MAAM+B,UAAU,GAAG,IAAI/B,MAAM,CAAC,CAAC;IAE/B,MAAMgC,CAAC,GAAGH,eAAe,GAAG,GAAG;IAC/B,IAAI,CAACvB,SAAS,CAACG,OAAO,CAAC,UAAUwB,QAAQ,EAAEC,CAAC,EAAE;MAC5C,IAAIC,IAAI,CAACC,MAAM,CAAC,CAAC,GAAGJ,CAAC,EAAE;QACrBF,WAAW,CAACxB,SAAS,CAACO,IAAI,CAACoB,QAAQ,CAAC;MACtC,CAAC,MAAM;QACLF,UAAU,CAACzB,SAAS,CAACO,IAAI,CAACoB,QAAQ,CAAC;MACrC;IACF,CAAC,CAAC;IACF,OAAO,CAACH,WAAW,EAAEC,UAAU,CAAC;EAClC;;EAEA;EACA;EACA;EACAM,OAAOA,CAAA,EAAI;IACT,IAAI,CAACC,cAAc,GAAG,CAAC,CAAC;IACxB,IAAI,CAACX,OAAO,GAAG,CAAC,CAAC;IACjB,IAAI,CAACtB,SAAS,GAAG,CAAC;IAElB,MAAME,IAAI,GAAG,IAAI;IACjB,IAAI,CAACD,SAAS,CAACG,OAAO,CAAC,UAAUwB,QAAQ,EAAE;MACzCA,QAAQ,CAACrB,WAAW,CAACH,OAAO,CAAC,UAAUY,KAAK,EAAE;QAC5Cd,IAAI,CAACF,SAAS,EAAE;;QAEhB;QACAE,IAAI,CAACoB,OAAO,CAACN,KAAK,CAACkB,GAAG,CAAC,GAAG,IAAI;;QAE9B;QACA,IAAI,CAAChC,IAAI,CAAC+B,cAAc,CAACjB,KAAK,CAACA,KAAK,CAAC,EAAE;UACrCd,IAAI,CAAC+B,cAAc,CAACjB,KAAK,CAACA,KAAK,CAAC,GAAG,CAAC,CAAC;QACvC;QACA,IAAI,CAACd,IAAI,CAAC+B,cAAc,CAACjB,KAAK,CAACA,KAAK,CAAC,CAACA,KAAK,CAACkB,GAAG,CAAC,EAAE;UAChDhC,IAAI,CAAC+B,cAAc,CAACjB,KAAK,CAACA,KAAK,CAAC,CAACA,KAAK,CAACkB,GAAG,CAAC,GAAG,CAAC;QACjD;QACAhC,IAAI,CAAC+B,cAAc,CAACjB,KAAK,CAACA,KAAK,CAAC,CAACA,KAAK,CAACkB,GAAG,CAAC,EAAE;MAC/C,CAAC,CAAC;IACJ,CAAC,CAAC;EACJ;;EAEA;EACA;EACAC,YAAYA,CAAA,EAAI;IACd,MAAMC,OAAO,GAAG,IAAI7C,OAAO,CAAC,CAAC;IAC7B,MAAMW,IAAI,GAAG,IAAI;IAEjB,IAAI,CAAC8B,OAAO,CAAC,CAAC;IACdZ,MAAM,CAACC,IAAI,CAAC,IAAI,CAACY,cAAc,CAAC,CAAC7B,OAAO,CAAC,UAAUY,KAAK,EAAE;MACxD,MAAMqB,SAAS,GAAGnC,IAAI,CAAC+B,cAAc,CAACjB,KAAK,CAAC;MAC5C,MAAMsB,UAAU,GAAGlB,MAAM,CAACC,IAAI,CAACgB,SAAS,CAAC;MAEzC,SAASE,kBAAkBA,CAAEC,CAAC,EAAEC,CAAC,EAAE;QACjC,IAAIJ,SAAS,CAACG,CAAC,CAAC,GAAGH,SAAS,CAACI,CAAC,CAAC,EAAE;UAC/B,OAAO,CAAC,CAAC;QACX,CAAC,MAAM;UACL,IAAIJ,SAAS,CAACG,CAAC,CAAC,GAAGH,SAAS,CAACI,CAAC,CAAC,EAAE;YAC/B,OAAO,CAAC;UACV,CAAC,MAAM;YACL,OAAO,CAAC;UACV;QACF;MACF;MAEA,MAAMC,gBAAgB,GAAGJ,UAAU,CAACK,IAAI,CAACJ,kBAAkB,CAAC;MAC5DH,OAAO,CAACQ,OAAO,CAAC5B,KAAK,EAAE0B,gBAAgB,CAAC;IAC1C,CAAC,CAAC;IACF,OAAON,OAAO;EAChB;EAEAF,GAAGA,CAAEE,OAAO,EAAE;IACZ,IAAI,CAACnC,SAAS,CAACG,OAAO,CAAC,UAAUwB,QAAQ,EAAE;MACzCA,QAAQ,CAACrB,WAAW,CAACH,OAAO,CAAC,UAAUY,KAAK,EAAE;QAC5C;QACAA,KAAK,CAAC6B,OAAO,GAAGT,OAAO,CAACU,OAAO,CAAC9B,KAAK,CAACA,KAAK,CAAC,CAAC,CAAC,CAAC;MACjD,CAAC,CAAC;IACJ,CAAC,CAAC;EACJ;EAEA+B,WAAWA,CAAA,EAAI;IACb,OAAO,IAAI,CAAC9C,SAAS,CAACQ,MAAM;EAC9B;EAEAuC,OAAOA,CAAA,EAAI;IACT,OAAO,IAAI,CAAChD,SAAS;EACvB;EAEAiD,gBAAgBA,CAAA,EAAI;IAClB,IAAIC,QAAQ,GAAG,EAAE;IACjB,IAAI,CAACjD,SAAS,CAACG,OAAO,CAAC,UAAUwB,QAAQ,EAAE;MACzCsB,QAAQ,GAAGtB,QAAQ,CAACqB,gBAAgB,CAACC,QAAQ,CAAC;IAChD,CAAC,CAAC;IACF;IACA,OAAOA,QAAQ;EACjB;EAEAC,WAAWA,CAAA,EAAI;IACb,IAAI,CAAClD,SAAS,CAACG,OAAO,CAAC,UAAUwB,QAAQ,EAAEwB,KAAK,EAAE;MAChD;MACA;IAAA,CACD,CAAC;EACJ;AACF;AAEAC,MAAM,CAACC,OAAO,GAAG3D,MAAM","ignoreList":[]},"metadata":{},"sourceType":"script","externalDependencies":[]}