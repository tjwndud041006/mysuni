{"ast":null,"code":"\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nconst lodash_1 = require(\"lodash\");\nconst phrase_1 = require(\"../data_structures/phrase\");\nconst strip_1 = require(\"./strip\");\nclass Parser {\n  constructor(stemmer, stopwords) {\n    this.stemmer = stemmer;\n    this.stopwords = stopwords;\n    this.phrases = [];\n    this.setNewPhraseCache();\n  }\n  process(wordArray) {\n    for (const phrase of wordArray) {\n      this.push(phrase.toLowerCase());\n    }\n    this.stemAll();\n    return this;\n  }\n  joinDuplicates() {\n    const groups = lodash_1.groupBy(this.phrases, 'text');\n    const resultList = [];\n    for (const text in groups) {\n      if (text) {\n        const group = groups[text];\n        const amount = group.length;\n        group[0].multiplyWith(amount);\n        resultList.push(group[0]);\n      }\n    }\n    this.phrases = resultList;\n  }\n  bestPhrases() {\n    const phrases = lodash_1.sortBy(this.phrases, ['score', 'text']).reverse();\n    const optimalAmount = Math.ceil(this.phrases.length / 3.0);\n    return lodash_1.map(lodash_1.take(phrases, optimalAmount), 'text');\n  }\n  push(phrase) {\n    for (const word of phrase.split(/\\s+/)) {\n      const strippedWord = strip_1.default(word);\n      const hasPunctuation = strippedWord !== word;\n      const isStopWord = this.stopwords.has(word);\n      if (isStopWord || word.length < 2) {\n        this.finalizePhraseCache();\n      } else if (hasPunctuation) {\n        this.cache.pushWord(strippedWord);\n        this.finalizePhraseCache();\n      } else {\n        this.cache.pushWord(strippedWord);\n      }\n    }\n  }\n  setNewPhraseCache() {\n    this.cache = new phrase_1.default();\n  }\n  finalizePhraseCache() {\n    if (!this.cache.isEmpty()) {\n      this.cache.createText();\n      this.phrases.push(this.cache);\n      this.setNewPhraseCache();\n    }\n  }\n  stemAll() {\n    for (const phrase of this.phrases) {\n      phrase.calculateStems(this.stemmer);\n    }\n  }\n}\nexports.default = Parser;","map":{"version":3,"names":["lodash_1","require","phrase_1","strip_1","Parser","constructor","stemmer","stopwords","phrases","setNewPhraseCache","process","wordArray","phrase","push","toLowerCase","stemAll","joinDuplicates","groups","groupBy","resultList","text","group","amount","length","multiplyWith","bestPhrases","sortBy","reverse","optimalAmount","Math","ceil","map","take","word","split","strippedWord","default","hasPunctuation","isStopWord","has","finalizePhraseCache","cache","pushWord","isEmpty","createText","calculateStems","exports"],"sources":["/Users/seojuyoung/sunic/project/frontend/node_modules/rake-js/src/lib/tools/parser.ts"],"sourcesContent":["import { groupBy, map, sortBy, take } from 'lodash'\nimport Phrase from '../data_structures/phrase'\nimport Stemmer from './stemmer'\nimport strip from './strip'\n\n/**\n * This Parser is able to take a bag of words (from a preprocessed text corpus)\n * and collect them into an array of Phrases. Phrases are n-grams of\n * subsequent words which may describe the corpus better than the individual\n * words standalone.\n */\nexport default class Parser {\n  // hold all results\n  public phrases: Phrase[] = []\n\n  // cache the last words until a phrase is completed\n  private cache: Phrase\n\n  // initialize with external plugins for word processing\n  constructor(private stemmer: Stemmer, private stopwords: Set<string>) {\n    this.setNewPhraseCache()\n  }\n\n  // execute a given word array and add the results to the internal corpora\n  public process(wordArray: string[]): Parser {\n    for (const phrase of wordArray) {\n      this.push(phrase.toLowerCase())\n    }\n    this.stemAll()\n    return this\n  }\n\n  public joinDuplicates() {\n    const groups = groupBy(this.phrases, 'text')\n    const resultList = []\n    for (const text in groups) {\n      if (text) {\n        const group = groups[text]\n        const amount = group.length\n        group[0].multiplyWith(amount)\n        resultList.push(group[0])\n      }\n    }\n    this.phrases = resultList\n  }\n\n  public bestPhrases(): string[] {\n    const phrases = sortBy(this.phrases, ['score', 'text']).reverse()\n    const optimalAmount = Math.ceil(this.phrases.length / 3.0)\n    return map(take(phrases, optimalAmount), 'text')\n  }\n\n  // add words to the internal phrase cache, or move on with the next phrase\n  private push(phrase: string) {\n    for (const word of phrase.split(/\\s+/)) {\n      const strippedWord = strip(word)\n      const hasPunctuation = strippedWord !== word\n      const isStopWord = this.stopwords.has(word)\n      if (isStopWord || word.length < 2) {\n        this.finalizePhraseCache()\n      } else if (hasPunctuation) {\n        this.cache.pushWord(strippedWord)\n        this.finalizePhraseCache()\n      } else {\n        this.cache.pushWord(strippedWord)\n      }\n    }\n  }\n\n  // reset the internal cache to a new blank object\n  private setNewPhraseCache() {\n    this.cache = new Phrase()\n  }\n\n  // move the internal cache into the result list, reset the cache\n  private finalizePhraseCache() {\n    if (!this.cache.isEmpty()) {\n      this.cache.createText()\n      this.phrases.push(this.cache)\n      this.setNewPhraseCache()\n    }\n  }\n\n  // stemm all words in all phrases\n  private stemAll() {\n    for (const phrase of this.phrases) {\n      phrase.calculateStems(this.stemmer)\n    }\n  }\n}\n"],"mappings":";;;;;AAAA,MAAAA,QAAA,GAAAC,OAAA;AACA,MAAAC,QAAA,GAAAD,OAAA;AAEA,MAAAE,OAAA,GAAAF,OAAA;AAQA,MAAAG,MAAA;EAQEC,YAAoBC,OAAgB,EAAUC,SAAsB;IAAhD,KAAAD,OAAO,GAAPA,OAAO;IAAmB,KAAAC,SAAS,GAATA,SAAS;IANhD,KAAAC,OAAO,GAAa,EAAE;IAO3B,IAAI,CAACC,iBAAiB,EAAE;EAC1B;EAGOC,OAAOA,CAACC,SAAmB;IAChC,KAAK,MAAMC,MAAM,IAAID,SAAS,EAAE;MAC9B,IAAI,CAACE,IAAI,CAACD,MAAM,CAACE,WAAW,EAAE,CAAC;IACjC;IACA,IAAI,CAACC,OAAO,EAAE;IACd,OAAO,IAAI;EACb;EAEOC,cAAcA,CAAA;IACnB,MAAMC,MAAM,GAAGjB,QAAA,CAAAkB,OAAO,CAAC,IAAI,CAACV,OAAO,EAAE,MAAM,CAAC;IAC5C,MAAMW,UAAU,GAAG,EAAE;IACrB,KAAK,MAAMC,IAAI,IAAIH,MAAM,EAAE;MACzB,IAAIG,IAAI,EAAE;QACR,MAAMC,KAAK,GAAGJ,MAAM,CAACG,IAAI,CAAC;QAC1B,MAAME,MAAM,GAAGD,KAAK,CAACE,MAAM;QAC3BF,KAAK,CAAC,CAAC,CAAC,CAACG,YAAY,CAACF,MAAM,CAAC;QAC7BH,UAAU,CAACN,IAAI,CAACQ,KAAK,CAAC,CAAC,CAAC,CAAC;MAC3B;IACF;IACA,IAAI,CAACb,OAAO,GAAGW,UAAU;EAC3B;EAEOM,WAAWA,CAAA;IAChB,MAAMjB,OAAO,GAAGR,QAAA,CAAA0B,MAAM,CAAC,IAAI,CAAClB,OAAO,EAAE,CAAC,OAAO,EAAE,MAAM,CAAC,CAAC,CAACmB,OAAO,EAAE;IACjE,MAAMC,aAAa,GAAGC,IAAI,CAACC,IAAI,CAAC,IAAI,CAACtB,OAAO,CAACe,MAAM,GAAG,GAAG,CAAC;IAC1D,OAAOvB,QAAA,CAAA+B,GAAG,CAAC/B,QAAA,CAAAgC,IAAI,CAACxB,OAAO,EAAEoB,aAAa,CAAC,EAAE,MAAM,CAAC;EAClD;EAGQf,IAAIA,CAACD,MAAc;IACzB,KAAK,MAAMqB,IAAI,IAAIrB,MAAM,CAACsB,KAAK,CAAC,KAAK,CAAC,EAAE;MACtC,MAAMC,YAAY,GAAGhC,OAAA,CAAAiC,OAAK,CAACH,IAAI,CAAC;MAChC,MAAMI,cAAc,GAAGF,YAAY,KAAKF,IAAI;MAC5C,MAAMK,UAAU,GAAG,IAAI,CAAC/B,SAAS,CAACgC,GAAG,CAACN,IAAI,CAAC;MAC3C,IAAIK,UAAU,IAAIL,IAAI,CAACV,MAAM,GAAG,CAAC,EAAE;QACjC,IAAI,CAACiB,mBAAmB,EAAE;MAC5B,CAAC,MAAM,IAAIH,cAAc,EAAE;QACzB,IAAI,CAACI,KAAK,CAACC,QAAQ,CAACP,YAAY,CAAC;QACjC,IAAI,CAACK,mBAAmB,EAAE;MAC5B,CAAC,MAAM;QACL,IAAI,CAACC,KAAK,CAACC,QAAQ,CAACP,YAAY,CAAC;MACnC;IACF;EACF;EAGQ1B,iBAAiBA,CAAA;IACvB,IAAI,CAACgC,KAAK,GAAG,IAAIvC,QAAA,CAAAkC,OAAM,EAAE;EAC3B;EAGQI,mBAAmBA,CAAA;IACzB,IAAI,CAAC,IAAI,CAACC,KAAK,CAACE,OAAO,EAAE,EAAE;MACzB,IAAI,CAACF,KAAK,CAACG,UAAU,EAAE;MACvB,IAAI,CAACpC,OAAO,CAACK,IAAI,CAAC,IAAI,CAAC4B,KAAK,CAAC;MAC7B,IAAI,CAAChC,iBAAiB,EAAE;IAC1B;EACF;EAGQM,OAAOA,CAAA;IACb,KAAK,MAAMH,MAAM,IAAI,IAAI,CAACJ,OAAO,EAAE;MACjCI,MAAM,CAACiC,cAAc,CAAC,IAAI,CAACvC,OAAO,CAAC;IACrC;EACF;;AA7EFwC,OAAA,CAAAV,OAAA,GAAAhC,MAAA","ignoreList":[]},"metadata":{},"sourceType":"script","externalDependencies":[]}